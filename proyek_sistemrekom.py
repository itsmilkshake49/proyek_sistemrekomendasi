# -*- coding: utf-8 -*-
"""proyek_sistemrekom.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VHh7Ci2d8T7DHGqW9BH_haUvvZMyomtF
"""

!pip install numpy==1.26.4 --force-reinstall

!pip install scikit-surprise

!pip install -q kaggle

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import accuracy

"""# **Load Data**"""

!mkdir ~/.kaggle
!echo '{"username":"laetishaharyanto","key":"8bf76bb9718e1557e200a90de3ca6a92"}' > ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d jahnavipaliwal/video-game-reviews-and-ratings

# Ekstrak file ZIP menggunakan unzip
!unzip -q video-game-reviews-and-ratings.zip -d video_game_reviews

df = pd.read_csv("video_game_reviews/video_game_reviews.csv")
df.head()

"""# **Data Understanding**"""

df.info()

"""**Insight**:  
Terdapat 18 Variabel untuk dataset game, namun untuk proyek sistem rekomendasi ini hanya menggunakan 3 variabel sebagai berikut:
- Game Title : Nama game
- Genre : Kategori game (misal: Action, Puzzle)
- User Rating : Penilaian dari pengguna
"""

# Deteksi Missing Values
df.isnull().sum()

"""**Insight**: Tidak terdapat Missing Values"""

# Deteksi Data Duplikat
print("Jumlah data duplikat:", df.duplicated().sum())

"""**Insight**: Tidak ada data duplikat

# **Exploratory Data Analysis**

### **Variabel Genre**
"""

print('Banyak Genre:', len(df['Genre'].unique()))
print('Genre:', df['Genre'].unique())

from wordcloud import WordCloud

def wordcloud(data, title):
    wc = WordCloud(width=800, height=400, max_words=200, background_color='white').generate(' '.join(data))
    plt.figure(figsize=(10, 8))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(title)
    plt.show()

wordcloud(df['Genre'], 'Genres')

"""**Insight**:
- 3 Genre Game terbanyak yaitu **Strategy**, **Shooter**, dan **RPG**

### **Variabel Rating**
"""

# Set style
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 5)

# Distribusi Rating
sns.histplot(df['User Rating'], bins=30, kde=True, color='skyblue')
plt.title('Distribusi User Rating')
plt.xlabel('User Rating')
plt.ylabel('Jumlah Game')
plt.show()

"""**Insight**:
- Bentuk distribusi terlihat mendekati normal (bell-shaped)
- Terdapat lebih dari 3000 game yang memiliki rating sekitar 30
- Karena rentang ratingnya dari 10-50 maka dibutuhkan penyekalaan ulang menjadi 1-5

# **Data Preparation**

## **Penyekalaan Variabel Rating**
"""

def ubah_skala(data, kolom, skala_lama=(10, 50), skala_baru=(1, 5)):
    min_lama, max_lama = skala_lama
    min_baru, max_baru = skala_baru
    return min_baru + ((data[kolom] - min_lama) / (max_lama - min_lama)) * (max_baru - min_baru)

df['User Rating'] = ubah_skala(df, 'User Rating', skala_lama=(10, 50), skala_baru=(1, 5))

"""## **Content-Based Filtering**"""

# Mulai dari data sebelum disatukan genre-nya
cbf = df.copy()

# Hapus duplikat berdasarkan 'Game Title'
cbf = cbf.drop_duplicates(subset='Game Title').reset_index(drop=True)

# Konversi kolom penting ke list
titles = cbf['Game Title'].tolist()
genres = cbf['Genre'].tolist()

# Buat DataFrame
cbf_df = pd.DataFrame({
    'id': range(len(titles)),        # id numerik unik
    'game_name': titles,             # nama game
    'genre': genres,                 # genre
})

cbf_df

"""### **TF-IDF**"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf
tf.fit(cbf_df['genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(cbf_df['genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre game
# Baris diisi dengan nama game

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=cbf_df.game_name
).sample(9, axis=1).sample(10, axis=0)

"""## **Collaborative Filtering**"""

# Reset index agar index jadi kolom
df_reset = df.reset_index()

# Ambil hanya kolom yang dibutuhkan
cf_df = df_reset[['index', 'Game Title', 'User Rating', 'Genre']].copy()

# Rename agar sesuai dengan konvensi: user, item, rating
cf_df.columns = ['userID', 'Game Title', 'User Rating', 'Genre']

# Buat Reader dengan range rating sesuai data
reader = Reader(rating_scale=(cf_df['User Rating'].min(), cf_df['User Rating'].max()))

# Buat dataset Surprise
data = Dataset.load_from_df(cf_df[['userID', 'Game Title', 'User Rating']], reader)

# Split data train-test
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""# **Model Development**

## **Content-Based Filtering**

### **Cosine Similarity**
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=cbf_df['game_name'], columns=cbf_df['game_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def game_recommendations(nama_game, similarity_data=cosine_sim_df, items=cbf_df[['game_name', 'genre']], k=5):

    # Pastikan nama_game ada di index similarity_data
    if nama_game not in similarity_data.index:
        raise ValueError(f"Game '{nama_game}' tidak ditemukan dalam data similarity.")

    # Cari posisi index game
    idx = similarity_data.columns.get_loc(nama_game)

    # Ambil index dari k game dengan similarity tertinggi (termasuk dirinya sendiri)
    index = similarity_data.iloc[:, idx].to_numpy().argpartition(range(-1, -k-1, -1))

    # Ambil nama game yang paling mirip berdasarkan index (urut dari paling mirip)
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Buang nama_game agar tidak rekomendasi ke diri sendiri
    closest = closest.drop(nama_game, errors='ignore')

    # Gabungkan dengan info game untuk tampilkan genre dll
    return pd.DataFrame(closest, columns=['game_name']).merge(items, on='game_name').head(k)

cbf_df[cbf_df.game_name.eq('Minecraft')]

# Mendapatkan rekomendasi game yang mirip dengan Minecraft
game_recommendations('Minecraft')

cbf_df[cbf_df.game_name.eq('Tekken 7')]

# Mendapatkan rekomendasi game yang mirip dengan Tekken 7
game_recommendations('Tekken 7')

"""### **Evaluasi**"""

def precision_recall_content_based(input_game, recommended_games, tfidf=tf, k=5):
    """
    Menghitung precision dan recall berbasis cosine similarity antar TF-IDF genre dari game input dan hasil rekomendasi.

    Parameters:
    - input_game: str, judul game sebagai input
    - recommended_games: list of str, hasil rekomendasi judul game
    - tfidf: TF-IDF vectorizer yang sudah dilatih
    - k: jumlah rekomendasi yang dinilai

    Returns:
    - precision dan recall dalam persentase
    """
    input_tfidf = tf.transform([cbf_df[cbf_df['game_name'] == input_game]['genre'].values[0]])
    rec_tfidf = tf.transform(cbf_df[cbf_df['game_name'].isin(recommended_games)]['genre'])

    sim_scores = cosine_similarity(input_tfidf, rec_tfidf)[0]

    precision = sum(sim_scores[:k]) / k
    recall = sum(sim_scores[:k]) / sum(sim_scores) if sum(sim_scores) > 0 else 0

    return precision * 100, recall * 100

# Pilih beberapa game sebagai contoh evaluasi
input_games = ["Minecraft", "Tekken 7"]

# Evaluasi precision dan recall untuk masing-masing input
for game in input_games:
    recommended_titles = list(game_recommendations(game, k=5)['game_name'])
    precision, recall = precision_recall_content_based(game, recommended_titles, k=5)

    print(f"\nEvaluasi untuk '{game}':")
    print(f"Precision@5: {precision:.2f}%")
    print(f"Recall@5: {recall:.2f}%")

"""## **Collaborative Filtering**"""

# Inisialisasi dan train model SVD
model = SVD()
model.fit(trainset)

def get_game_recommendations(user_id, df, model, top_n=10):
    user_rated_games = df[df['userID'] == user_id]['Game Title'].unique()
    all_games = df['Game Title'].unique()
    unrated_games = np.setdiff1d(all_games, user_rated_games)

    predictions = [model.predict(user_id, game) for game in unrated_games]
    predictions.sort(key=lambda x: x.est, reverse=True)

    recommended_game_titles = [pred.iid for pred in predictions[:top_n]]
    recommendations = df[df['Game Title'].isin(recommended_game_titles)][['Game Title', 'Genre']].drop_duplicates(subset=['Game Title'])
    return recommendations.reset_index(drop=True)

# Contoh rekomendasi untuk user 331
rekomendasi_user_331 = get_game_recommendations(user_id=331, df=cf_df, model=model)
print(rekomendasi_user_331)

# Contoh rekomendasi untuk user 20
rekomendasi_user_20 = get_game_recommendations(user_id=20, df=cf_df, model=model)
print(rekomendasi_user_20)

"""### **Evaluasi**"""

# Evaluasi model
predictions = model.test(testset)
print("Root Mean Squared Error (RMSE):", accuracy.rmse(predictions))
print("Mean Absolute Error (MAE):", accuracy.mae(predictions))